{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "texture.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWtvMF3jScIipOnrGoRAGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linjiw/linjiw.github.io/blob/main/texture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "94zVjFposXQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d1d800-29c6-4984-bb97-d10db54503ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/poincloud/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ise4BQBDtHt",
        "outputId": "de0fd2fb-60a2-449c-d20a-6faae6be8c42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/poincloud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTtqJnPuDw86",
        "outputId": "8c93fda3-ba41-47e8-be00-5a36ff7a1a27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'all_file (1).gsheet'\n",
            "'all_file (2).gsheet'\n",
            " all_file.csv\n",
            " all_file.gsheet\n",
            " DCGAN.ipynb\n",
            " \u001b[0m\u001b[01;34mdtd\u001b[0m/\n",
            " model_epoch_100_07_02_2022_07_31_27.pth\n",
            " model_epoch_10_07_02_2022_06_34_02.pth\n",
            " model_epoch_10_07_02_2022_14_44_27.pth\n",
            " model_epoch_10_07_02_2022_17_24_20.pth\n",
            " model_epoch_101_07_02_2022_07_32_05.pth\n",
            " model_epoch_102_07_02_2022_07_32_43.pth\n",
            " model_epoch_103_07_02_2022_07_33_20.pth\n",
            " model_epoch_104_07_02_2022_07_33_58.pth\n",
            " model_epoch_105_07_02_2022_07_34_36.pth\n",
            " model_epoch_106_07_02_2022_07_35_15.pth\n",
            " model_epoch_1_07_02_2022_06_28_16.pth\n",
            " model_epoch_1_07_02_2022_14_37_30.pth\n",
            " model_epoch_1_07_02_2022_16_16_49.pth\n",
            " model_epoch_1_07_02_2022_16_50_57.pth\n",
            " model_epoch_107_07_02_2022_07_35_53.pth\n",
            " model_epoch_108_07_02_2022_07_36_31.pth\n",
            " model_epoch_109_07_02_2022_07_37_09.pth\n",
            " model_epoch_110_07_02_2022_07_37_48.pth\n",
            " model_epoch_11_07_02_2022_06_34_40.pth\n",
            " model_epoch_11_07_02_2022_14_45_14.pth\n",
            " model_epoch_11_07_02_2022_17_28_03.pth\n",
            " model_epoch_111_07_02_2022_07_38_26.pth\n",
            " model_epoch_112_07_02_2022_07_39_04.pth\n",
            " model_epoch_113_07_02_2022_07_39_42.pth\n",
            " model_epoch_114_07_02_2022_07_40_20.pth\n",
            " model_epoch_115_07_02_2022_07_40_59.pth\n",
            " model_epoch_116_07_02_2022_07_41_37.pth\n",
            " model_epoch_117_07_02_2022_07_42_15.pth\n",
            " model_epoch_118_07_02_2022_07_42_54.pth\n",
            " model_epoch_119_07_02_2022_07_43_32.pth\n",
            " model_epoch_120_07_02_2022_07_44_10.pth\n",
            " model_epoch_12_07_02_2022_06_35_18.pth\n",
            " model_epoch_12_07_02_2022_14_46_00.pth\n",
            " model_epoch_12_07_02_2022_17_31_43.pth\n",
            " model_epoch_121_07_02_2022_07_44_49.pth\n",
            " model_epoch_122_07_02_2022_07_45_27.pth\n",
            " model_epoch_123_07_02_2022_07_46_06.pth\n",
            " model_epoch_124_07_02_2022_07_46_44.pth\n",
            " model_epoch_125_07_02_2022_07_47_22.pth\n",
            " model_epoch_126_07_02_2022_07_48_00.pth\n",
            " model_epoch_127_07_02_2022_07_48_37.pth\n",
            " model_epoch_128_07_02_2022_07_49_15.pth\n",
            " model_epoch_129_07_02_2022_07_49_52.pth\n",
            " model_epoch_130_07_02_2022_07_50_30.pth\n",
            " model_epoch_13_07_02_2022_06_35_56.pth\n",
            " model_epoch_13_07_02_2022_14_46_47.pth\n",
            " model_epoch_13_07_02_2022_17_35_24.pth\n",
            " model_epoch_131_07_02_2022_07_51_09.pth\n",
            " model_epoch_132_07_02_2022_07_51_48.pth\n",
            " model_epoch_133_07_02_2022_07_52_27.pth\n",
            " model_epoch_134_07_02_2022_07_53_06.pth\n",
            " model_epoch_135_07_02_2022_07_53_45.pth\n",
            " model_epoch_136_07_02_2022_07_54_24.pth\n",
            " model_epoch_137_07_02_2022_07_55_02.pth\n",
            " model_epoch_138_07_02_2022_07_55_42.pth\n",
            " model_epoch_139_07_02_2022_07_56_20.pth\n",
            " model_epoch_140_07_02_2022_07_56_59.pth\n",
            " model_epoch_14_07_02_2022_06_36_35.pth\n",
            " model_epoch_14_07_02_2022_14_47_33.pth\n",
            " model_epoch_14_07_02_2022_17_39_03.pth\n",
            " model_epoch_141_07_02_2022_07_57_37.pth\n",
            " model_epoch_142_07_02_2022_07_58_15.pth\n",
            " model_epoch_143_07_02_2022_07_58_53.pth\n",
            " model_epoch_144_07_02_2022_07_59_31.pth\n",
            " model_epoch_145_07_02_2022_08_00_09.pth\n",
            " model_epoch_146_07_02_2022_08_00_47.pth\n",
            " model_epoch_147_07_02_2022_08_01_26.pth\n",
            " model_epoch_148_07_02_2022_08_02_05.pth\n",
            " model_epoch_149_07_02_2022_08_02_44.pth\n",
            " model_epoch_150_07_02_2022_08_03_24.pth\n",
            " model_epoch_15_07_02_2022_06_37_13.pth\n",
            " model_epoch_15_07_02_2022_14_48_19.pth\n",
            " model_epoch_15_07_02_2022_17_42_43.pth\n",
            " model_epoch_151_07_02_2022_08_04_03.pth\n",
            " model_epoch_152_07_02_2022_08_04_43.pth\n",
            " model_epoch_153_07_02_2022_08_05_22.pth\n",
            " model_epoch_154_07_02_2022_08_06_02.pth\n",
            " model_epoch_155_07_02_2022_08_06_41.pth\n",
            " model_epoch_156_07_02_2022_08_07_21.pth\n",
            " model_epoch_157_07_02_2022_08_08_00.pth\n",
            " model_epoch_158_07_02_2022_08_08_40.pth\n",
            " model_epoch_159_07_02_2022_08_09_20.pth\n",
            " model_epoch_160_07_02_2022_08_10_00.pth\n",
            " model_epoch_16_07_02_2022_06_37_51.pth\n",
            " model_epoch_16_07_02_2022_14_49_05.pth\n",
            " model_epoch_16_07_02_2022_17_46_24.pth\n",
            " model_epoch_161_07_02_2022_08_10_39.pth\n",
            " model_epoch_162_07_02_2022_08_11_19.pth\n",
            " model_epoch_163_07_02_2022_08_11_58.pth\n",
            " model_epoch_164_07_02_2022_08_12_38.pth\n",
            " model_epoch_165_07_02_2022_08_13_17.pth\n",
            " model_epoch_166_07_02_2022_08_13_57.pth\n",
            " model_epoch_167_07_02_2022_08_14_36.pth\n",
            " model_epoch_168_07_02_2022_08_15_16.pth\n",
            " model_epoch_169_07_02_2022_08_15_55.pth\n",
            " model_epoch_170_07_02_2022_08_16_35.pth\n",
            " model_epoch_17_07_02_2022_06_38_29.pth\n",
            " model_epoch_17_07_02_2022_14_49_51.pth\n",
            " model_epoch_17_07_02_2022_17_50_04.pth\n",
            " model_epoch_171_07_02_2022_08_17_15.pth\n",
            " model_epoch_172_07_02_2022_08_17_54.pth\n",
            " model_epoch_173_07_02_2022_08_18_34.pth\n",
            " model_epoch_174_07_02_2022_08_19_14.pth\n",
            " model_epoch_175_07_02_2022_08_19_54.pth\n",
            " model_epoch_176_07_02_2022_08_20_33.pth\n",
            " model_epoch_177_07_02_2022_08_21_13.pth\n",
            " model_epoch_178_07_02_2022_08_21_53.pth\n",
            " model_epoch_179_07_02_2022_08_22_33.pth\n",
            " model_epoch_180_07_02_2022_08_23_12.pth\n",
            " model_epoch_18_07_02_2022_06_39_08.pth\n",
            " model_epoch_18_07_02_2022_14_50_37.pth\n",
            " model_epoch_18_07_02_2022_17_53_46.pth\n",
            " model_epoch_181_07_02_2022_08_23_52.pth\n",
            " model_epoch_182_07_02_2022_08_24_32.pth\n",
            " model_epoch_183_07_02_2022_08_25_11.pth\n",
            " model_epoch_184_07_02_2022_08_25_51.pth\n",
            " model_epoch_185_07_02_2022_08_26_30.pth\n",
            " model_epoch_186_07_02_2022_08_27_09.pth\n",
            " model_epoch_187_07_02_2022_08_27_48.pth\n",
            " model_epoch_188_07_02_2022_08_28_27.pth\n",
            " model_epoch_189_07_02_2022_08_29_06.pth\n",
            " model_epoch_190_07_02_2022_08_29_45.pth\n",
            " model_epoch_19_07_02_2022_06_39_47.pth\n",
            " model_epoch_19_07_02_2022_14_51_23.pth\n",
            " model_epoch_19_07_02_2022_17_57_27.pth\n",
            " model_epoch_191_07_02_2022_08_30_25.pth\n",
            " model_epoch_192_07_02_2022_08_31_04.pth\n",
            " model_epoch_193_07_02_2022_08_31_43.pth\n",
            " model_epoch_194_07_02_2022_08_32_22.pth\n",
            " model_epoch_195_07_02_2022_08_33_01.pth\n",
            " model_epoch_196_07_02_2022_08_33_40.pth\n",
            " model_epoch_197_07_02_2022_08_34_20.pth\n",
            " model_epoch_198_07_02_2022_08_34_59.pth\n",
            " model_epoch_199_07_02_2022_08_35_38.pth\n",
            " model_epoch_200_07_02_2022_08_36_17.pth\n",
            " model_epoch_20_07_02_2022_06_40_25.pth\n",
            " model_epoch_20_07_02_2022_14_52_09.pth\n",
            " model_epoch_20_07_02_2022_18_01_08.pth\n",
            " model_epoch_201_07_02_2022_08_36_57.pth\n",
            " model_epoch_202_07_02_2022_08_37_36.pth\n",
            " model_epoch_203_07_02_2022_08_38_15.pth\n",
            " model_epoch_204_07_02_2022_08_38_54.pth\n",
            " model_epoch_205_07_02_2022_08_39_33.pth\n",
            " model_epoch_206_07_02_2022_08_40_13.pth\n",
            " model_epoch_2_07_02_2022_06_28_54.pth\n",
            " model_epoch_2_07_02_2022_14_38_16.pth\n",
            " model_epoch_2_07_02_2022_16_20_46.pth\n",
            " model_epoch_2_07_02_2022_16_54_39.pth\n",
            " model_epoch_207_07_02_2022_08_40_52.pth\n",
            " model_epoch_208_07_02_2022_08_41_31.pth\n",
            " model_epoch_209_07_02_2022_08_42_10.pth\n",
            " model_epoch_210_07_02_2022_08_42_49.pth\n",
            " model_epoch_21_07_02_2022_06_41_04.pth\n",
            " model_epoch_21_07_02_2022_14_52_55.pth\n",
            " model_epoch_21_07_02_2022_18_04_49.pth\n",
            " model_epoch_211_07_02_2022_08_43_28.pth\n",
            " model_epoch_212_07_02_2022_08_44_07.pth\n",
            " model_epoch_213_07_02_2022_08_44_46.pth\n",
            " model_epoch_214_07_02_2022_08_45_25.pth\n",
            " model_epoch_215_07_02_2022_08_46_04.pth\n",
            " model_epoch_216_07_02_2022_08_46_43.pth\n",
            " model_epoch_217_07_02_2022_08_47_22.pth\n",
            " model_epoch_218_07_02_2022_08_48_01.pth\n",
            " model_epoch_219_07_02_2022_08_48_40.pth\n",
            " model_epoch_220_07_02_2022_08_49_19.pth\n",
            " model_epoch_22_07_02_2022_06_41_43.pth\n",
            " model_epoch_22_07_02_2022_14_53_41.pth\n",
            " model_epoch_22_07_02_2022_18_08_29.pth\n",
            " model_epoch_221_07_02_2022_08_49_58.pth\n",
            " model_epoch_222_07_02_2022_08_50_37.pth\n",
            " model_epoch_223_07_02_2022_08_51_16.pth\n",
            " model_epoch_224_07_02_2022_08_51_54.pth\n",
            " model_epoch_225_07_02_2022_08_52_33.pth\n",
            " model_epoch_226_07_02_2022_08_53_11.pth\n",
            " model_epoch_227_07_02_2022_08_53_50.pth\n",
            " model_epoch_228_07_02_2022_08_54_28.pth\n",
            " model_epoch_229_07_02_2022_08_55_07.pth\n",
            " model_epoch_230_07_02_2022_08_55_45.pth\n",
            " model_epoch_23_07_02_2022_06_42_22.pth\n",
            " model_epoch_23_07_02_2022_14_54_27.pth\n",
            " model_epoch_23_07_02_2022_18_12_07.pth\n",
            " model_epoch_231_07_02_2022_08_56_24.pth\n",
            " model_epoch_232_07_02_2022_08_57_03.pth\n",
            " model_epoch_233_07_02_2022_08_57_42.pth\n",
            " model_epoch_234_07_02_2022_08_58_20.pth\n",
            " model_epoch_235_07_02_2022_08_58_59.pth\n",
            " model_epoch_236_07_02_2022_08_59_38.pth\n",
            " model_epoch_237_07_02_2022_09_00_16.pth\n",
            " model_epoch_238_07_02_2022_09_00_55.pth\n",
            " model_epoch_239_07_02_2022_09_01_34.pth\n",
            " model_epoch_240_07_02_2022_09_02_12.pth\n",
            " model_epoch_24_07_02_2022_06_43_01.pth\n",
            " model_epoch_24_07_02_2022_14_55_13.pth\n",
            " model_epoch_24_07_02_2022_18_15_49.pth\n",
            " model_epoch_241_07_02_2022_09_02_51.pth\n",
            " model_epoch_242_07_02_2022_09_03_29.pth\n",
            " model_epoch_243_07_02_2022_09_04_08.pth\n",
            " model_epoch_244_07_02_2022_09_04_47.pth\n",
            " model_epoch_245_07_02_2022_09_05_26.pth\n",
            " model_epoch_246_07_02_2022_09_06_04.pth\n",
            " model_epoch_247_07_02_2022_09_06_43.pth\n",
            " model_epoch_248_07_02_2022_09_07_22.pth\n",
            " model_epoch_249_07_02_2022_09_08_01.pth\n",
            " model_epoch_250_07_02_2022_09_08_40.pth\n",
            " model_epoch_25_07_02_2022_06_43_40.pth\n",
            " model_epoch_25_07_02_2022_14_55_59.pth\n",
            " model_epoch_25_07_02_2022_18_19_33.pth\n",
            " model_epoch_251_07_02_2022_09_09_18.pth\n",
            " model_epoch_252_07_02_2022_09_09_57.pth\n",
            " model_epoch_253_07_02_2022_09_10_36.pth\n",
            " model_epoch_254_07_02_2022_09_11_14.pth\n",
            " model_epoch_255_07_02_2022_09_11_54.pth\n",
            " model_epoch_256_07_02_2022_09_12_32.pth\n",
            " model_epoch_257_07_02_2022_09_13_11.pth\n",
            " model_epoch_258_07_02_2022_09_13_50.pth\n",
            " model_epoch_259_07_02_2022_09_14_29.pth\n",
            " model_epoch_260_07_02_2022_09_15_08.pth\n",
            " model_epoch_26_07_02_2022_06_44_19.pth\n",
            " model_epoch_26_07_02_2022_14_56_45.pth\n",
            " model_epoch_26_07_02_2022_18_23_17.pth\n",
            " model_epoch_261_07_02_2022_09_15_46.pth\n",
            " model_epoch_262_07_02_2022_09_16_25.pth\n",
            " model_epoch_263_07_02_2022_09_17_04.pth\n",
            " model_epoch_264_07_02_2022_09_17_43.pth\n",
            " model_epoch_265_07_02_2022_09_18_23.pth\n",
            " model_epoch_266_07_02_2022_09_19_01.pth\n",
            " model_epoch_267_07_02_2022_09_19_40.pth\n",
            " model_epoch_268_07_02_2022_09_20_19.pth\n",
            " model_epoch_269_07_02_2022_09_20_58.pth\n",
            " model_epoch_270_07_02_2022_09_21_37.pth\n",
            " model_epoch_27_07_02_2022_06_44_58.pth\n",
            " model_epoch_27_07_02_2022_14_57_31.pth\n",
            " model_epoch_27_07_02_2022_18_26_59.pth\n",
            " model_epoch_271_07_02_2022_09_22_16.pth\n",
            " model_epoch_272_07_02_2022_09_22_55.pth\n",
            " model_epoch_273_07_02_2022_09_23_33.pth\n",
            " model_epoch_274_07_02_2022_09_24_12.pth\n",
            " model_epoch_275_07_02_2022_09_24_51.pth\n",
            " model_epoch_276_07_02_2022_09_25_30.pth\n",
            " model_epoch_277_07_02_2022_09_26_08.pth\n",
            " model_epoch_278_07_02_2022_09_26_47.pth\n",
            " model_epoch_279_07_02_2022_09_27_26.pth\n",
            " model_epoch_280_07_02_2022_09_28_06.pth\n",
            " model_epoch_28_07_02_2022_06_45_37.pth\n",
            " model_epoch_28_07_02_2022_14_58_17.pth\n",
            " model_epoch_28_07_02_2022_18_30_44.pth\n",
            " model_epoch_281_07_02_2022_09_28_45.pth\n",
            " model_epoch_282_07_02_2022_09_29_25.pth\n",
            " model_epoch_283_07_02_2022_09_30_04.pth\n",
            " model_epoch_284_07_02_2022_09_30_43.pth\n",
            " model_epoch_285_07_02_2022_09_31_22.pth\n",
            " model_epoch_286_07_02_2022_09_32_02.pth\n",
            " model_epoch_287_07_02_2022_09_32_41.pth\n",
            " model_epoch_288_07_02_2022_09_33_21.pth\n",
            " model_epoch_289_07_02_2022_09_34_00.pth\n",
            " model_epoch_290_07_02_2022_09_34_39.pth\n",
            " model_epoch_29_07_02_2022_06_46_16.pth\n",
            " model_epoch_29_07_02_2022_14_59_03.pth\n",
            " model_epoch_29_07_02_2022_18_34_29.pth\n",
            " model_epoch_291_07_02_2022_09_35_19.pth\n",
            " model_epoch_292_07_02_2022_09_35_58.pth\n",
            " model_epoch_293_07_02_2022_09_36_37.pth\n",
            " model_epoch_294_07_02_2022_09_37_17.pth\n",
            " model_epoch_295_07_02_2022_09_37_57.pth\n",
            " model_epoch_296_07_02_2022_09_38_36.pth\n",
            " model_epoch_297_07_02_2022_09_39_16.pth\n",
            " model_epoch_298_07_02_2022_09_39_55.pth\n",
            " model_epoch_299_07_02_2022_09_40_35.pth\n",
            " model_epoch_300_07_02_2022_09_41_14.pth\n",
            " model_epoch_30_07_02_2022_06_46_55.pth\n",
            " model_epoch_30_07_02_2022_14_59_49.pth\n",
            " model_epoch_30_07_02_2022_18_38_15.pth\n",
            " model_epoch_3_07_02_2022_06_29_32.pth\n",
            " model_epoch_3_07_02_2022_14_39_02.pth\n",
            " model_epoch_3_07_02_2022_16_24_44.pth\n",
            " model_epoch_3_07_02_2022_16_58_22.pth\n",
            " model_epoch_31_07_02_2022_06_47_33.pth\n",
            " model_epoch_31_07_02_2022_15_00_35.pth\n",
            " model_epoch_31_07_02_2022_18_42_00.pth\n",
            " model_epoch_32_07_02_2022_06_48_11.pth\n",
            " model_epoch_32_07_02_2022_15_01_21.pth\n",
            " model_epoch_32_07_02_2022_18_45_46.pth\n",
            " model_epoch_33_07_02_2022_06_48_49.pth\n",
            " model_epoch_33_07_02_2022_15_02_08.pth\n",
            " model_epoch_33_07_02_2022_18_49_33.pth\n",
            " model_epoch_34_07_02_2022_06_49_27.pth\n",
            " model_epoch_34_07_02_2022_15_02_53.pth\n",
            " model_epoch_34_07_02_2022_18_53_16.pth\n",
            " model_epoch_35_07_02_2022_06_50_05.pth\n",
            " model_epoch_35_07_02_2022_15_03_39.pth\n",
            " model_epoch_35_07_02_2022_18_56_59.pth\n",
            " model_epoch_36_07_02_2022_06_50_43.pth\n",
            " model_epoch_36_07_02_2022_15_04_25.pth\n",
            " model_epoch_36_07_02_2022_19_00_44.pth\n",
            " model_epoch_37_07_02_2022_06_51_21.pth\n",
            " model_epoch_37_07_02_2022_15_05_10.pth\n",
            " model_epoch_37_07_02_2022_19_04_27.pth\n",
            " model_epoch_38_07_02_2022_06_51_59.pth\n",
            " model_epoch_38_07_02_2022_15_05_56.pth\n",
            " model_epoch_38_07_02_2022_19_08_09.pth\n",
            " model_epoch_39_07_02_2022_06_52_38.pth\n",
            " model_epoch_39_07_02_2022_15_06_44.pth\n",
            " model_epoch_39_07_02_2022_19_11_56.pth\n",
            " model_epoch_40_07_02_2022_06_53_16.pth\n",
            " model_epoch_40_07_02_2022_15_07_33.pth\n",
            " model_epoch_40_07_02_2022_19_15_40.pth\n",
            " model_epoch_4_07_02_2022_06_30_11.pth\n",
            " model_epoch_4_07_02_2022_14_39_49.pth\n",
            " model_epoch_4_07_02_2022_16_28_41.pth\n",
            " model_epoch_4_07_02_2022_17_02_05.pth\n",
            " model_epoch_41_07_02_2022_06_53_54.pth\n",
            " model_epoch_41_07_02_2022_15_08_21.pth\n",
            " model_epoch_41_07_02_2022_19_19_28.pth\n",
            " model_epoch_42_07_02_2022_06_54_32.pth\n",
            " model_epoch_42_07_02_2022_15_09_10.pth\n",
            " model_epoch_42_07_02_2022_19_23_14.pth\n",
            " model_epoch_43_07_02_2022_06_55_10.pth\n",
            " model_epoch_43_07_02_2022_15_09_58.pth\n",
            " model_epoch_43_07_02_2022_19_27_01.pth\n",
            " model_epoch_44_07_02_2022_06_55_49.pth\n",
            " model_epoch_44_07_02_2022_15_10_46.pth\n",
            " model_epoch_44_07_02_2022_19_30_47.pth\n",
            " model_epoch_45_07_02_2022_06_56_27.pth\n",
            " model_epoch_45_07_02_2022_15_11_35.pth\n",
            " model_epoch_45_07_02_2022_19_34_32.pth\n",
            " model_epoch_46_07_02_2022_06_57_05.pth\n",
            " model_epoch_46_07_02_2022_15_12_24.pth\n",
            " model_epoch_46_07_02_2022_19_38_16.pth\n",
            " model_epoch_47_07_02_2022_06_57_44.pth\n",
            " model_epoch_47_07_02_2022_15_13_14.pth\n",
            " model_epoch_47_07_02_2022_19_41_59.pth\n",
            " model_epoch_48_07_02_2022_06_58_22.pth\n",
            " model_epoch_48_07_02_2022_15_14_04.pth\n",
            " model_epoch_48_07_02_2022_19_45_42.pth\n",
            " model_epoch_49_07_02_2022_06_59_00.pth\n",
            " model_epoch_49_07_02_2022_15_14_53.pth\n",
            " model_epoch_49_07_02_2022_19_49_26.pth\n",
            " model_epoch_50_07_02_2022_06_59_38.pth\n",
            " model_epoch_50_07_02_2022_15_15_43.pth\n",
            " model_epoch_50_07_02_2022_19_53_13.pth\n",
            " model_epoch_5_07_02_2022_06_30_49.pth\n",
            " model_epoch_5_07_02_2022_14_40_35.pth\n",
            " model_epoch_5_07_02_2022_16_32_39.pth\n",
            " model_epoch_5_07_02_2022_17_05_45.pth\n",
            " model_epoch_51_07_02_2022_07_00_16.pth\n",
            " model_epoch_51_07_02_2022_15_16_32.pth\n",
            " model_epoch_52_07_02_2022_07_00_55.pth\n",
            " model_epoch_52_07_02_2022_15_17_22.pth\n",
            " model_epoch_53_07_02_2022_07_01_33.pth\n",
            " model_epoch_53_07_02_2022_15_18_12.pth\n",
            " model_epoch_54_07_02_2022_07_02_11.pth\n",
            " model_epoch_54_07_02_2022_15_19_00.pth\n",
            " model_epoch_55_07_02_2022_07_02_50.pth\n",
            " model_epoch_55_07_02_2022_15_19_50.pth\n",
            " model_epoch_56_07_02_2022_07_03_28.pth\n",
            " model_epoch_56_07_02_2022_15_20_40.pth\n",
            " model_epoch_57_07_02_2022_07_04_06.pth\n",
            " model_epoch_58_07_02_2022_07_04_45.pth\n",
            " model_epoch_59_07_02_2022_07_05_23.pth\n",
            " model_epoch_60_07_02_2022_07_06_01.pth\n",
            " model_epoch_6_07_02_2022_06_31_29.pth\n",
            " model_epoch_6_07_02_2022_14_41_22.pth\n",
            " model_epoch_6_07_02_2022_17_09_26.pth\n",
            " model_epoch_61_07_02_2022_07_06_39.pth\n",
            " model_epoch_62_07_02_2022_07_07_18.pth\n",
            " model_epoch_63_07_02_2022_07_07_56.pth\n",
            " model_epoch_64_07_02_2022_07_08_34.pth\n",
            " model_epoch_65_07_02_2022_07_09_12.pth\n",
            " model_epoch_66_07_02_2022_07_09_50.pth\n",
            " model_epoch_67_07_02_2022_07_10_28.pth\n",
            " model_epoch_68_07_02_2022_07_11_06.pth\n",
            " model_epoch_69_07_02_2022_07_11_43.pth\n",
            " model_epoch_70_07_02_2022_07_12_21.pth\n",
            " model_epoch_7_07_02_2022_06_32_07.pth\n",
            " model_epoch_7_07_02_2022_14_42_08.pth\n",
            " model_epoch_7_07_02_2022_17_13_09.pth\n",
            " model_epoch_71_07_02_2022_07_12_59.pth\n",
            " model_epoch_72_07_02_2022_07_13_37.pth\n",
            " model_epoch_73_07_02_2022_07_14_16.pth\n",
            " model_epoch_74_07_02_2022_07_14_54.pth\n",
            " model_epoch_75_07_02_2022_07_15_32.pth\n",
            " model_epoch_76_07_02_2022_07_16_10.pth\n",
            " model_epoch_77_07_02_2022_07_16_48.pth\n",
            " model_epoch_78_07_02_2022_07_17_26.pth\n",
            " model_epoch_79_07_02_2022_07_18_05.pth\n",
            " model_epoch_80_07_02_2022_07_18_43.pth\n",
            " model_epoch_8_07_02_2022_06_32_45.pth\n",
            " model_epoch_8_07_02_2022_14_42_54.pth\n",
            " model_epoch_8_07_02_2022_17_16_52.pth\n",
            " model_epoch_81_07_02_2022_07_19_22.pth\n",
            " model_epoch_82_07_02_2022_07_20_00.pth\n",
            " model_epoch_83_07_02_2022_07_20_38.pth\n",
            " model_epoch_84_07_02_2022_07_21_16.pth\n",
            " model_epoch_85_07_02_2022_07_21_54.pth\n",
            " model_epoch_86_07_02_2022_07_22_33.pth\n",
            " model_epoch_87_07_02_2022_07_23_11.pth\n",
            " model_epoch_88_07_02_2022_07_23_49.pth\n",
            " model_epoch_89_07_02_2022_07_24_27.pth\n",
            " model_epoch_90_07_02_2022_07_25_06.pth\n",
            " model_epoch_9_07_02_2022_06_33_23.pth\n",
            " model_epoch_9_07_02_2022_14_43_41.pth\n",
            " model_epoch_9_07_02_2022_17_20_36.pth\n",
            " model_epoch_91_07_02_2022_07_25_44.pth\n",
            " model_epoch_92_07_02_2022_07_26_22.pth\n",
            " model_epoch_93_07_02_2022_07_27_00.pth\n",
            " model_epoch_94_07_02_2022_07_27_38.pth\n",
            " model_epoch_95_07_02_2022_07_28_17.pth\n",
            " model_epoch_96_07_02_2022_07_28_55.pth\n",
            " model_epoch_97_07_02_2022_07_29_33.pth\n",
            " model_epoch_98_07_02_2022_07_30_11.pth\n",
            " model_epoch_99_07_02_2022_07_30_50.pth\n",
            " \u001b[01;34mruns\u001b[0m/\n",
            " test_file.csv\n",
            " texture.ipynb\n",
            " train_file.csv\n",
            " train_file.gsheet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LIB_PTH = \"dtd/\"\n",
        "img = \"images\"\n",
        "labels = \"labels\""
      ],
      "metadata": {
        "id": "AzAaB-aItcHL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "# from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# from torchvision import transforms"
      ],
      "metadata": {
        "id": "t9fF-2_wvSHa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getmp(LIB_PTH,img):\n",
        "  kind = os.listdir(os.path.join(LIB_PTH,img))\n",
        "  mp = {}\n",
        "  count = 0\n",
        "  for i in kind:\n",
        "    \n",
        "    mp[i] = count\n",
        "    count+=1\n",
        "  # print(count)\n",
        "  return mp\n",
        "mp = getmp(LIB_PTH,img)"
      ],
      "metadata": {
        "id": "CB01fqm6vf5g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getcsv(LIB_PTH,img,mp):\n",
        "  filename = \"train_file.csv\"\n",
        "  test_name = \"test_file.csv\"\n",
        "  file1 = open(filename,\"w\")\n",
        "  file1.write(f\"label,pth\\n\")\n",
        "  file2 = open(test_name,\"w\")\n",
        "  file2.write(f\"label,pth\\n\")\n",
        "  test_num = 12\n",
        "  for i in os.listdir(os.path.join(LIB_PTH,img)):\n",
        "    label = mp[i]\n",
        "    count =0\n",
        "    # test_num = 12\n",
        "\n",
        "    for idx, j in enumerate(os.listdir(os.path.join(LIB_PTH,img,i))):\n",
        "      if (j.endswith('.jpg') or j.endswith('.png') or j.endswith('.jpeg')) and idx>=test_num:\n",
        "        file1.write(f\"{label},{os.path.join(img,i,j)}\\n\")\n",
        "        count+=1\n",
        "      elif (j.endswith('.jpg') or j.endswith('.png') or j.endswith('.jpeg')):\n",
        "        file2.write(f\"{label},{os.path.join(img,i,j)}\\n\")\n",
        "    # print(count)\n",
        "  file1.close()\n",
        "  file2.close()\n",
        "  return filename\n",
        "annotation = getcsv(LIB_PTH,img,mp)\n",
        "\n"
      ],
      "metadata": {
        "id": "o9_3uTGpCZsp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir=None, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
        "        # img_path = self.img_labels.iloc[idx, 1]\n",
        "        image = read_image(img_path)\n",
        "        # print(image.shape)\n",
        "        label = self.img_labels.iloc[idx, 0]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            # print()\n",
        "        if self.target_transform:\n",
        "            label = self.target\n",
        "        label = int(label)\n",
        "        # print(type(label))\n",
        "        return image,label"
      ],
      "metadata": {
        "id": "m7TxaOaGuylF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_kl_loss(p, q, pad_mask=None):\n",
        "    \n",
        "    p_loss = torch.nn.functional.kl_div(torch.nn.functional.log_softmax(p, dim=-1), torch.nn.functional.softmax(q, dim=-1), reduction='none')\n",
        "    q_loss = torch.nn.functional.kl_div(torch.nn.functional.log_softmax(q, dim=-1), torch.nn.functional.softmax(p, dim=-1), reduction='none')\n",
        "    # p_loss = torch.nn.functional.kl_div(p,q, reduction='none')\n",
        "    # q_loss = torch.nn.functional.kl_div(q,p, reduction='none')\n",
        " \n",
        "    # pad_mask is for seq-level tasks\n",
        "    if pad_mask is not None:\n",
        "        p_loss.masked_fill_(pad_mask, 0.)\n",
        "        q_loss.masked_fill_(pad_mask, 0.)\n",
        "\n",
        "    # You can choose whether to use function \"sum\" and \"mean\" depending on your task\n",
        "    p_loss = p_loss.mean()\n",
        "    q_loss = q_loss.mean()\n",
        "\n",
        "    loss = (p_loss + q_loss) / 2\n",
        "    return loss\n",
        "def train(args, model, device, train_samples, optimizer,scheduler, criterion, epoch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    train_loader = torch.utils.data.DataLoader(train_samples, batch_size=args['batch_size'], shuffle=True)\n",
        "        # print(f\"X.shape: {X.shape}\")\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # print(f\"batch_idx: {batch_idx} data {data.shape}\")\n",
        "        data = data.to(device)\n",
        "        # print(target)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "            \n",
        "        output = model(data)\n",
        "        # logits = model(data)\n",
        "            \n",
        "        # logits2 = model(data)\n",
        "\n",
        "        #     # cross entropy loss for classifier\n",
        "        # ce_loss = 0.5 * (criterion(logits, target) + criterion(logits2, target))\n",
        "\n",
        "        # kl_loss = compute_kl_loss(logits, logits2)\n",
        "\n",
        "        #     # carefully choose hyper-parameters\n",
        "        # loss = ce_loss + 5 * kl_loss\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "    # scheduler.step()\n",
        "    return loss.cpu().detach().numpy()\n",
        "def test(args, model, device, dev_samples,criterion):\n",
        "    model.eval()\n",
        "    true_y_list = []\n",
        "    pred_y_list = []\n",
        "    with torch.no_grad():\n",
        "        # for i in range(len(dev_samples)):\n",
        "            # X, Y = dev_samples[i]\n",
        "\n",
        "            # test_items = LibriItems(X, Y, context=args['context'])\n",
        "        test_loader = torch.utils.data.DataLoader(dev_samples, batch_size=args['batch_size'], shuffle=False)\n",
        "\n",
        "        for data, true_y in test_loader:\n",
        "            data = data.to(device)\n",
        "            true_y = true_y.to(device)                \n",
        "                \n",
        "            output = model(data)\n",
        "            pred_y = torch.argmax(output, axis=1)\n",
        "                \n",
        "            loss = criterion(output, true_y)\n",
        "\n",
        "            pred_y_list.extend(pred_y.tolist())\n",
        "            true_y_list.extend(true_y.tolist())\n",
        "    train_accuracy =  accuracy_score(true_y_list, pred_y_list)\n",
        "    \n",
        "    return train_accuracy , loss.cpu().detach().numpy()\n",
        "def savemodel(model,epoch):\n",
        "    now = datetime.now()\n",
        "    name = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
        "    torch.save(model.state_dict(), f\"model_epoch_{epoch}_{name}.pth\")\n",
        "def main(args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(device)\n",
        "    # model = Network(args['context']).to(device)\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
        "    # model = args['model']\n",
        "    train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.ColorJitter(brightness=.5, hue=.3),\n",
        "    torchvision.transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
        "    torchvision.transforms.RandomRotation(degrees=(0, 180)),\n",
        "    torchvision.transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
        "    torchvision.transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
        "    torchvision.transforms.RandomAutocontrast(),\n",
        "    torchvision.transforms.RandomCrop((224,224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    \n",
        "    ])\n",
        "    test_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.RandomCrop((224,224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    \n",
        "    ])\n",
        "    num_classes = 47\n",
        "    model = models.vgg16(pretrained=False)\n",
        "    # model.fc = nn.Linear(512 , 47)\n",
        "    model.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=0.9)\n",
        "    \n",
        "    scheduler1 = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "    train_set = CustomImageDataset(\"train_file.csv\", img_dir=\"dtd\",transform=train_transform)\n",
        "    test_set = CustomImageDataset(\"test_file.csv\", img_dir=\"dtd\",transform=test_transform)\n",
        "    # train_set,test_set, val_set = torch.utils.data.random_split(dataset = allset,lengths = [allset.__len__()-200,100,100])\n",
        "\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # If you want to use full Dataset, please pass None to csvpath\n",
        "    # train_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"train-clean-100\", csvpath=\"./train_filenames_subset_8192_v2.csv\")\n",
        " \n",
        "    writer = SummaryWriter()\n",
        "    for epoch in range(1, args['epoch'] + 1):\n",
        "        train_loss = train(args, model, device, train_set, optimizer,scheduler1, criterion, epoch,)\n",
        "        test_acc, test_loss = test(args, model, device, test_set,criterion)\n",
        "        print('Dev accuracy ', test_acc)\n",
        "        savemodel(model,epoch)\n",
        "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "        writer.add_scalar('Loss/test', train_loss, epoch)\n",
        "\n",
        "        writer.add_scalar('Acc/test', test_acc, epoch)"
      ],
      "metadata": {
        "id": "1aPu6Daume2c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    args = {\n",
        "        'batch_size': 32,\n",
        "        'log_interval': 30,\n",
        "        'lr': 0.1,\n",
        "        'epoch': 300\n",
        "    }\n",
        "    main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "ZO57E3GCpP6s",
        "outputId": "255622a6-33cc-483e-fd4f-99df23ed646b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Train Epoch: 1 [0/5076 (0%)]\tLoss: 3.847721\n",
            "Train Epoch: 1 [960/5076 (19%)]\tLoss: 3.827791\n",
            "Train Epoch: 1 [1920/5076 (38%)]\tLoss: 3.873753\n",
            "Train Epoch: 1 [2880/5076 (57%)]\tLoss: 3.842206\n",
            "Train Epoch: 1 [3840/5076 (75%)]\tLoss: 3.888655\n",
            "Train Epoch: 1 [4800/5076 (94%)]\tLoss: 3.859903\n",
            "Dev accuracy  0.02127659574468085\n",
            "Train Epoch: 2 [0/5076 (0%)]\tLoss: 3.850024\n",
            "Train Epoch: 2 [960/5076 (19%)]\tLoss: 3.898536\n",
            "Train Epoch: 2 [1920/5076 (38%)]\tLoss: 3.872771\n",
            "Train Epoch: 2 [2880/5076 (57%)]\tLoss: 3.840858\n",
            "Train Epoch: 2 [3840/5076 (75%)]\tLoss: 3.874823\n",
            "Train Epoch: 2 [4800/5076 (94%)]\tLoss: 3.850205\n",
            "Dev accuracy  0.02127659574468085\n",
            "Train Epoch: 3 [0/5076 (0%)]\tLoss: 3.866397\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-77ecb6973ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     }\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-c6071796ac2a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dev accuracy '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c6071796ac2a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_samples, optimizer, scheduler, criterion, epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print(f\"X.shape: {X.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# print(f\"batch_idx: {batch_idx} data {data.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-38cb7c775fbc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m# print()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1906\u001b[0m         \"\"\"\n\u001b[1;32m   1907\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1908\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_sharpness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharpness_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1909\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36madjust_sharpness\u001b[0;34m(img, sharpness_factor)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \"\"\"\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_sharpness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharpness_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_sharpness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharpness_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36madjust_sharpness\u001b[0;34m(img, sharpness_factor)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0menhancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharpness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharpness_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageEnhance.py\u001b[0m in \u001b[0;36menhance\u001b[0;34m(self, factor)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegenerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mblend\u001b[0;34m(im1, im2, alpha)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m     \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}