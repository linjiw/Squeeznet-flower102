{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Res1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFMO+yY/GHNGAjLshCq1FD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linjiw/linjiw.github.io/blob/main/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zNoPQiJCxjEe"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"username\",\"key\":\"key\"}') # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c 11-785-s22-hw3p2\n",
        "! unzip 11-785-s22-hw3p2.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hxeTuOodxxe0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "# your key"
      ],
      "metadata": {
        "id": "p2dWtpkXx0fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "!pip install torchsummaryX # We also install a summary package to check our model's forward before training"
      ],
      "metadata": {
        "id": "jcnvUVrox6CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from os.path import join\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import phonemes\n",
        "# imports for decoding and distance calculation\n",
        "import ctcdecode\n",
        "import Levenshtein\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "import csv\n",
        "import time\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "# from tqdm import tqdm_notebook as tqdm\n",
        "import kaggle\n",
        "import wandb\n",
        "import torchaudio\n",
        "wandb.init(project=\"HW3\", entity=\"linjiw\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)\n",
        "# !jupyter nbextension enable --py widgetsnbextension\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "9tJJGVqcx9T3",
        "outputId": "1e23909e-51e8-44f2-d035-2b68e5992b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinjiw\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220406_024959-16xn00ji</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/linjiw/HW3/runs/16xn00ji\" target=\"_blank\">captain-phage-144</a></strong> to <a href=\"https://wandb.ai/linjiw/HW3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PHONEME_MAP = [\n",
        "    \" \",\n",
        "    \".\", #SIL\n",
        "    \"a\", #AA\n",
        "    \"A\", #AE\n",
        "    \"h\", #AH\n",
        "    \"o\", #AO\n",
        "    \"w\", #AW\n",
        "    \"y\", #AY\n",
        "    \"b\", #B\n",
        "    \"c\", #CH\n",
        "    \"d\", #D\n",
        "    \"D\", #DH\n",
        "    \"e\", #EH\n",
        "    \"r\", #ER\n",
        "    \"E\", #EY\n",
        "    \"f\", #F\n",
        "    \"g\", #G\n",
        "    \"H\", #H\n",
        "    \"i\", #IH \n",
        "    \"I\", #IY\n",
        "    \"j\", #JH\n",
        "    \"k\", #K\n",
        "    \"l\", #L\n",
        "    \"m\", #M\n",
        "    \"n\", #N\n",
        "    \"N\", #NG\n",
        "    \"O\", #OW\n",
        "    \"Y\", #OY\n",
        "    \"p\", #P \n",
        "    \"R\", #R\n",
        "    \"s\", #S\n",
        "    \"S\", #SH\n",
        "    \"t\", #T\n",
        "    \"T\", #TH\n",
        "    \"u\", #UH\n",
        "    \"U\", #UW\n",
        "    \"v\", #V\n",
        "    \"W\", #W\n",
        "    \"?\", #Y\n",
        "    \"z\", #Z\n",
        "    \"Z\" #ZH\n",
        "]\n",
        "phe_dict = {}\n",
        "tensor_dict = {}\n",
        "PHONEMES = phonemes.PHONEMES\n",
        "for idx, i in enumerate(PHONEMES):\n",
        "    phe_dict[i] = PHONEME_MAP[idx]\n",
        "    tensor_dict[PHONEME_MAP[idx]] = idx\n",
        "\n",
        "def maplst(lst):\n",
        "    res =[]\n",
        "    for i in lst:\n",
        "        res.append(phe_dict[i])\n",
        "    res = np.array(res)\n",
        "    # res = res.astype(np.float)\n",
        "    return np.array(res)\n",
        "def maptotensor(lst):\n",
        "    res =[]\n",
        "    for i in lst:\n",
        "        res.append(tensor_dict[i])\n",
        "    res = np.array(res)\n",
        "    # res = res.astype(np.float)\n",
        "    return np.array(res)\n",
        "\n",
        "# %%\n",
        "lst = ['B', 'IH', 'K', 'SH', 'AA']\n",
        "res = maplst(lst)\n",
        "tsr = maptotensor(res)\n",
        "print(res)\n",
        "print(tsr)\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "# %%\n",
        "# This cell is where your actual TODOs start\n",
        "# You will need to implement the Dataset class by your own. You may also implement it similar to HW1P2 (dont require context)\n",
        "# The steps for implementation given below are how we have implemented it.\n",
        "# However, you are welcomed to do it your own way if it is more comfortable or efficient. \n",
        "\n",
        "\n",
        "# freqmask = \n",
        "# timemask = torchaudio.transforms.TimeMasking(time_mask_param=2)\n",
        "freqmask =  torchaudio.transforms.FrequencyMasking(freq_mask_param=13)\n",
        "        # print(X.shape)\n",
        "        \n",
        "# X = timemask(X)\n",
        "#          = freqmask(X\n",
        "transform = nn.Sequential(freqmask)\n",
        "\n",
        "# transform = nn.Sequential(timemask)\n",
        "\n",
        "class LibriSamples(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, partition= \"train\"): # You can use partition to specify train or dev\n",
        "        \n",
        "\n",
        "        self.partition =  partition\n",
        "        self.X_dir = os.path.join(data_path,partition,\"mfcc/\")# TODO: get mfcc directory path\n",
        "        self.Y_dir = os.path.join(data_path,partition,\"transcript/\")# TODO: get transcript path\n",
        "\n",
        "        self.X_files = os.listdir(self.X_dir)# TODO: list files in the mfcc directory\n",
        "        self.Y_files = os.listdir(self.Y_dir)# TODO: list files in the transcript directory\n",
        "\n",
        "        # TODO: store PHONEMES from phonemes.py inside the class. phonemes.py will be downloaded from kaggle.\n",
        "        # You may wish to store PHONEMES as a class attribute or a global variable as well.\n",
        "        self.PHONEMES = phonemes.PHONEMES\n",
        "\n",
        "        assert(len(self.X_files) == len(self.Y_files))\n",
        "\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_files)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        X_path = self.X_dir + self.X_files[ind]\n",
        "        Y_path = self.Y_dir + self.Y_files[ind]\n",
        "        X = np.load(X_path)\n",
        "        X = torch.from_numpy(X)# TODO: Load the mfcc npy file at the specified index ind in the directory\n",
        "        # Y = maplst(np.load(Y_path)[1:-1])# TODO: Load the corresponding transcripts\n",
        "    #    )\n",
        "        if self.partition == \"train\":\n",
        "            X= transform(X)\n",
        "        Y = np.load(Y_path)[1:-1]\n",
        "        # print(Y)\n",
        "        # print(Y.shape)\n",
        "        # Y2 = PHONEMES.index(i) for i in np.load(Y_path)[1:-1]\n",
        "        # print(f\"Y {Y}\")\n",
        "        # print(f\"Y2 {Y2}\")\n",
        "        # Remember, the transcripts are a sequence of phonemes. Eg. np.array(['<sos>', 'B', 'IH', 'K', 'SH', 'AA', '<eos>'])\n",
        "        # You need to convert these into a sequence of Long tensors\n",
        "        # Tip: You may need to use self.PHONEMES\n",
        "        # Remember, PHONEMES or PHONEME_MAP do not have '<sos>' or '<eos>' but the transcripts have them. \n",
        "        # You need to remove '<sos>' and '<eos>' from the trancripts. \n",
        "        # Inefficient way is to use a for loop for this. Efficient way is to think that '<sos>' occurs at the start and '<eos>' occurs at the end.\n",
        "        Yy = torch.LongTensor([PHONEMES.index(i) for i in Y])\n",
        "        # Yy = torch.Tensor(maptotensor(Y)).type(torch.LongTensor)# TODO: Convert sequence of  phonemes into sequence of Long tensors\n",
        "        # print(f\"X {X.shape}\")\n",
        "        # print(f\"Y {Y.shape}\")\n",
        "        return X, Yy\n",
        "    \n",
        "    def collate_fn(self,batch):\n",
        "\n",
        "        batch_x = [x for x,y in batch]\n",
        "        batch_y = [y for x,y in batch]\n",
        "\n",
        "        # print(batch_x[0].shape)\n",
        "        # batch_x = transform(batch_x)\n",
        "        new_lst = []\n",
        "        for idx, i in enumerate(batch_x):\n",
        "            new_lst.append(batch_x[idx])\n",
        "        batch_x_pad = pad_sequence(new_lst)\n",
        "        # batch_x_pad = pad_sequence([i for i in batch_x], batch_first=False)# TODO: pad the sequence with pad_sequence (already imported)\n",
        "        lengths_x = [len(i) for i in batch_x]# TODO: Get original lengths of the sequence before padding\n",
        "        lengths_x_pad = [len(i) for i in batch_x_pad]\n",
        "\n",
        "        \n",
        "        # print(f\"batch_x {batch_x}\")\n",
        "        \n",
        "\n",
        "        # print(f\"test_pad.len {test_pad.shape}\")\n",
        "        # print(f\"batch_x.len {len(batch_x)}\")\n",
        "        # print(f\"lengths_x {lengths_x}\")\n",
        "        # print(f\"lengths_x_pad {lengths_x_pad}\")\n",
        "\n",
        "        new_lst = []\n",
        "        for idx, i in enumerate(batch_y):\n",
        "            new_lst.append(batch_y[idx])\n",
        "        batch_y_pad = pad_sequence(new_lst)\n",
        "\n",
        "        # batch_y_pad = pad_sequence(batch_y) # TODO: pad the sequence with pad_sequence (already imported)\n",
        "        lengths_y = [len(i) for i in batch_y] # TODO: Get original lengths of the sequence before padding\n",
        "\n",
        "        return batch_x_pad, batch_y_pad, torch.tensor(lengths_x), torch.tensor(lengths_y)\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "# You can either try to combine test data in the previous class or write a new Dataset class for test data\n",
        "class LibriSamplesTest(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, test_order): # test_order is the csv similar to what you used in hw1\n",
        "        self.data_path = data_path\n",
        "        test_csv_pth = os.path.join(data_path,'test',test_order)\n",
        "        subset = list(pd.read_csv(test_csv_pth).file)\n",
        "        # subset = self.parse_csv(test_csv_pth)\n",
        "        test_order_list = subset# TODO: open test_order.csv as a list\n",
        "        self.X_names = [i for i in subset]# TODO: Load the npy files from test_order.csv and append into a list\n",
        "        # You can load the files here or save the paths here and load inside __getitem__ like the previous class\n",
        "    @staticmethod\n",
        "    def parse_csv(filepath):\n",
        "        subset = []\n",
        "        with open(filepath) as f:\n",
        "            f_csv = csv.reader(f)\n",
        "            for row in f_csv:\n",
        "                subset.append(row[0])\n",
        "        return subset[0:]\n",
        "    def __len__(self):\n",
        "        return len(self.X_names)\n",
        "    \n",
        "    def __getitem__(self, ind):\n",
        "        # TODOs: Need to return only X because this is the test dataset\n",
        "        X_path = os.path.join(self.data_path,'test','mfcc',self.X_names[ind])\n",
        "        X = torch.Tensor(np.load(X_path))\n",
        "        return X\n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "        batch_x = [x for x in batch]\n",
        "        new_lst = []\n",
        "        for idx, i in enumerate(batch_x):\n",
        "            new_lst.append(batch_x[idx])\n",
        "        batch_x_pad = pad_sequence(new_lst)\n",
        "        # batch_x_pad = pad_sequence([i for i in batch_x], batch_first=False)# TODO: pad the sequence with pad_sequence (already imported)\n",
        "        lengths_x = [len(i) for i in batch_x]# TODO: Get original lengths of the sequence before padding\n",
        "        # lengths_x_pad = [len(i) for i in batch_x_pad]\n",
        "        # batch_x = [x for x in batch]\n",
        "        # batch_x_pad = pad_sequence(batch_x)# TODO: pad the sequence with pad_sequence (already imported)\n",
        "        # lengths_x = [len(i) for i in batch_x]# TODO: Get original lengths of the sequence before padding\n",
        "\n",
        "        return batch_x_pad, torch.tensor(lengths_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcIk7VsYyiCY",
        "outputId": "e1bd91da-121a-4e08-9d41-39e9dbf9a039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['b' 'i' 'k' 'S' 'a']\n",
            "[ 8 18 21 31  2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResBlock\n",
        "\n",
        "Resblock is one of my experiment, and it can reach to 6.3 using 4 resblock and 4 lstm later with GELU.\n",
        "\n",
        "The resblock is used to prevent gradient vanishing using skip connection."
      ],
      "metadata": {
        "id": "TPQJ6rSMHSYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ResBlock(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Iniialize a residual block with two convolutions followed by batchnorm layers\n",
        "    \"\"\"\n",
        "    def __init__(self,channel=256):\n",
        "        super().__init__()\n",
        "\n",
        "        # self.conv1 = nn.Conv1d(256,256,kernel_size = 3,stride= 1,padding=1)\n",
        "        # self.conv2 = nn.Conv1d(256,256,kernel_size = 3,stride= 1,padding=1)\n",
        "        # # self.layernorm1 = nn.LayerNorm(())\n",
        "        # self.batchnorm1 = nn.BatchNorm1d(256)\n",
        "        # self.batchnorm2 = nn.BatchNorm1d(256)\n",
        "        self.oneblock = nn.Sequential(nn.Conv1d(channel,channel,kernel_size = 1,stride= 1,padding=0),nn.GELU(),nn.BatchNorm1d(channel),nn.Conv1d(channel,channel,kernel_size = 1,stride= 1,padding=0),nn.GELU(),nn.BatchNorm1d(channel))\n",
        "\n",
        "    def convblock(self, x):\n",
        "        # x = F.gelu(self.batchnorm1(self.conv1(x)))\n",
        "        # x = F.gelu(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.oneblock(x)\n",
        "        return x\n",
        "   \n",
        "    \"\"\"\n",
        "    Combine output with the original input\n",
        "    \"\"\"\n",
        "    def forward(self, x): return x + self.convblock(x) # skip connection\n",
        "\n",
        "\n",
        "class DepBlock(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Iniialize a residual block with two convolutions followed by batchnorm layers\n",
        "    \"\"\"\n",
        "    def __init__(self,channel=256):\n",
        "        super().__init__()\n",
        "\n",
        "        # self.conv1 = nn.Conv1d(256,256,kernel_size = 3,stride= 1,padding=1)\n",
        "        # self.conv2 = nn.Conv1d(256,256,kernel_size = 3,stride= 1,padding=1)\n",
        "        # # self.layernorm1 = nn.LayerNorm(())\n",
        "        # self.batchnorm1 = nn.BatchNorm1d(256)\n",
        "        # self.batchnorm2 = nn.BatchNorm1d(256)\n",
        "        expand_ratio = 4\n",
        "        self.oneblock = nn.Sequential(nn.Conv1d(channel,expand_ratio*channel,kernel_size = 3,stride= 1,padding=1,groups=channel),nn.GELU(),nn.BatchNorm1d(expand_ratio*channel),\n",
        "                                      nn.Conv1d(expand_ratio*channel,channel,kernel_size = 1,stride= 1,padding=0),nn.GELU(),nn.BatchNorm1d(channel))\n",
        "\n",
        "    def convblock(self, x):\n",
        "        # x = F.gelu(self.batchnorm1(self.conv1(x)))\n",
        "        # x = F.gelu(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.oneblock(x)\n",
        "        return x\n",
        "   \n",
        "    \"\"\"\n",
        "    Combine output with the original input\n",
        "    \"\"\"\n",
        "    def forward(self, x): return x + self.convblock(x) # skip connection\n",
        "\n",
        "class Network_v1(nn.Module):\n",
        "\n",
        "    def __init__(self): # You can add any extra arguments as you wish\n",
        "\n",
        "        super(Network_v1, self).__init__()\n",
        "\n",
        "        # Embedding layer converts the raw input into features which may (or may not) help the LSTM to learn better \n",
        "        # For the very low cut-off you dont require an embedding layer. You can pass the input directly to the  LSTM\n",
        "        # self.embedding = \n",
        "        # self.cnn = nn.Sequential(nn.Conv1d(13,128,kernel_size = 1,stride= 2),nn.BatchNorm1d(128),nn.Conv1d(128,256,kernel_size = 1,stride= 1),nn.BatchNorm1d(256))\n",
        "        channel = 256\n",
        "        self.layernorm0 = nn.LayerNorm(13)\n",
        "        self.cnn1 = nn.Sequential(nn.Conv1d(13,channel,kernel_size = 3,stride= 1,padding=1),nn.BatchNorm1d(channel))\n",
        "        self.res = nn.Sequential(*[DepBlock(channel) for i in range(2)])\n",
        "        \n",
        "        # self.mlp = nn.Linear(channel,256)\n",
        "        lstm_nn = 512\n",
        "        self.lstm = nn.LSTM(input_size=256,hidden_size= lstm_nn,bidirectional =True, num_layers= 4,dropout=0.25)# TODO: # Create a single layer, uni-directional LSTM with hidden_size = 256\n",
        "        # Use nn.LSTM() Make sure that you give in the proper arguments as given in https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        # self.layernorm = nn.LayerNorm(512)\n",
        "        self.classification = nn.Sequential(nn.Linear(lstm_nn*2,4096),nn.GELU(),nn.Dropout(p=0.3),nn.Linear(4096,41))# TODO: Create a single classification layer using nn.Linear()\n",
        "\n",
        "    def forward(self, x, lx): # TODO: You need to pass atleast 1 more parameter apart from self and x\n",
        "\n",
        "        # x is returned from the dataloader. So it is assumed to be padded with the help of the collate_fn\n",
        "        # print(x.shape)\n",
        "        # x = self.layernorm0(x)\n",
        "        x = self.cnn1(x.permute(1,2,0))\n",
        "        x = self.res(x)\n",
        "        x = x.permute(2,0,1)\n",
        "\n",
        "        # x = self.mlp(x)\n",
        "        # print(x.shape)\n",
        "        \n",
        "        \n",
        "        packed_input = pack_padded_sequence(x,lx,enforce_sorted=False)# TODO: Pack the input with pack_padded_sequence. Look at the parameters it requires\n",
        "\n",
        "        out1, (out2, out3) = self.lstm(packed_input)# TODO: Pass packed input to self.lstm\n",
        "        # As you may see from the LSTM docs, LSTM returns 3 vectors. Which one do you need to pass to the next function?\n",
        "        out, lengths  = pad_packed_sequence(out1)# TODO: Need to 'unpack' the LSTM output using pad_packed_sequence\n",
        "        \n",
        "        # out = out.permute(1,0,2)\n",
        "        # print(out.shape)\n",
        "        # out = self.layernorm(out)\n",
        "\n",
        "        out = self.classification(out)# TODO: Pass unpacked LSTM output to the classification layer\n",
        "        # out = # Optional: Do log softmax on the output. Which dimension?\n",
        "        # print(out[0,0,:])\n",
        "        out = torch.nn.functional.log_softmax(out,dim=2)\n",
        "        # print(out[0,0,:])\n",
        "        # print(sum(out[0,0,:]))\n",
        "        return out, lengths # TODO: Need to return 2 variables"
      ],
      "metadata": {
        "id": "XnI8mUEKyMv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linjinn\n",
        "Here is my experiment with my own network, it comes with the intuition from mobilenet and convnext of the depthwise convolution and the skip normal convolution. And since it has some downsample, so I changed the forward part to clamp the lx length."
      ],
      "metadata": {
        "id": "uPhqsF8qHv8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class linjinn(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(nn.Conv1d(13,64,kernel_size = 1,stride= 1),nn.BatchNorm1d(64),nn.GELU(),nn.Conv1d(64,64,kernel_size = 1,stride= 1,padding=0,groups=64),\n",
        "                            # nn.GELU(),\n",
        "                            nn.BatchNorm1d(64),\n",
        "                            nn.Conv1d(64,64*4,kernel_size = 1,stride= 1),\n",
        "                            nn.GELU(),\n",
        "                            # nn.BatchNorm1d(64*4),\n",
        "                            nn.Conv1d(64*4,64*4,kernel_size = 1,stride= 1,padding=0,groups=64*4),\n",
        "                            # nn.GELU(),\n",
        "                            nn.BatchNorm1d(64*4),\n",
        "                            nn.Conv1d(64*4,128,kernel_size = 1,stride= 1),\n",
        "                            nn.GELU(),\n",
        "                            # nn.BatchNorm1d(128),\n",
        "                            nn.MaxPool1d(kernel_size=3,stride=2, padding=1),\n",
        "                            nn.Conv1d(128,128,kernel_size = 3,stride= 1,padding=1,groups=128),\n",
        "                            nn.BatchNorm1d(128),\n",
        "                            nn.Conv1d(128,256,kernel_size = 1,stride= 1),\n",
        "                            nn.GELU(),\n",
        "                            )\n",
        "        self.lstm = nn.LSTM(input_size=256,hidden_size= 512,bidirectional =True, num_layers= 5,dropout=0.2)\n",
        "        self.classification = nn.Sequential(nn.Linear(512*2,4096),nn.GELU(),nn.Dropout(p=0.2),nn.Linear(4096,41))\n",
        "    def forward(self, x, lx):\n",
        "        # print(x.shape)\n",
        "        # print()\n",
        "        max_lx = x.shape[0]//2\n",
        "        lx = torch.clamp(lx,max = max_lx)\n",
        "        x = self.cnn(x.permute(1,2,0))\n",
        "        # x = self.res(x)\n",
        "        # x = self.mapback(x)\n",
        "        x = x.permute(2,0,1)\n",
        "\n",
        "        # x = self.mlp(x)\n",
        "        # print(x.shape)\n",
        "        \n",
        "        \n",
        "        packed_input = pack_padded_sequence(x,lx,enforce_sorted=False)# TODO: Pack the input with pack_padded_sequence. Look at the parameters it requires\n",
        "\n",
        "        out1, (out2, out3) = self.lstm(packed_input)# TODO: Pass packed input to self.lstm\n",
        "        # As you may see from the LSTM docs, LSTM returns 3 vectors. Which one do you need to pass to the next function?\n",
        "        out, lengths  = pad_packed_sequence(out1)# TODO: Need to 'unpack' the LSTM output using pad_packed_sequence\n",
        "        \n",
        "        # out = out.permute(1,0,2)\n",
        "        # print(out.shape)\n",
        "        # out = self.layernorm(out)\n",
        "\n",
        "        out = self.classification(out)# TODO: Pass unpacked LSTM output to the classification layer\n",
        "        # out = # Optional: Do log softmax on the output. Which dimension?\n",
        "        # print(out[0,0,:])\n",
        "        out = torch.nn.functional.log_softmax(out,dim=2)\n",
        "        # print(out[0,0,:])\n",
        "        # print(sum(out[0,0,:]))\n",
        "        return out, lengths # TODO: Need to return 2 variables"
      ],
      "metadata": {
        "id": "Fk6gLyYsx0Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = linjinn()\n",
        "lr = 0.0020\n",
        "# lr = 5e-4\n",
        "batch_size = 48\n",
        "epochs = 100\n",
        "num_classes = 41\n",
        "wandb.config = {\n",
        "  \"learning_rate\": lr,\n",
        "  \"epochs\": epochs,\n",
        "  \"batch_size\": batch_size\n",
        "}\n",
        "\n",
        "root = 'hw3p2_student_data/hw3p2_student_data' # TODO: Where your hw3p2_student_data folder is\n",
        "\n",
        "train_data = LibriSamples(root, 'train')\n",
        "val_data = LibriSamples(root, 'dev')\n",
        "test_data = LibriSamplesTest(root, 'test_order.csv')\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=False,collate_fn=train_data.collate_fn, num_workers=8)# TODO: Define the train loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=False,collate_fn=val_data.collate_fn, num_workers=8)# TODO: Define the val loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "test_loader = DataLoader(test_data,batch_size=batch_size,shuffle=False,collate_fn=test_data.collate_fn, num_workers=8)# TODO: Define the test loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Batch size: \", batch_size)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n",
        "\n",
        "criterion = nn.CTCLoss()# TODO: What loss do you need for sequence to sequence models? \n",
        "# Do you need to transpose or permute the model output to find out the loss? Read its documentation\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-3)# TODO: Adam works well with LSTM (use lr = 2e-3)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=5e-4)\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr=0.02,momentum=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=3,factor=0.7)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "decoder = ctcdecode.CTCBeamDecoder(labels = PHONEME_MAP,\n",
        "    model_path=None,\n",
        "    alpha=0,\n",
        "    beta=0,\n",
        "    cutoff_top_n=40,\n",
        "    cutoff_prob=1.0,\n",
        "    beam_width=1,\n",
        "    num_processes=8,\n",
        "    blank_id=0,\n",
        "    log_probs_input=True)# TODO: Intialize the CTC beam decoder\n",
        "# Check out https://github.com/parlance/ctcdecode for the details on how to implement decoding\n",
        "# Do you need to give log_probs_input = True or False?\n",
        "def pred(h,lh,decoder,PHONEME_MAP):\n",
        "    h = h.permute(1, 0, 2)\n",
        "    beam_results, _, _, out_lens = decoder.decode(h,seq_lens=lh)\n",
        "    h_string_lst = []\n",
        "    batch_s = h.shape[0]\n",
        "    for i in range(batch_s): \n",
        "\n",
        "        h_sliced = beam_results[i][0][:out_lens[i,0]]\n",
        "        h_string = \"\".join([PHONEME_MAP[j] for j in h_sliced])\n",
        "        h_string_lst.append(h_string)\n",
        "    return h_string_lst\n",
        "def calculate_levenshtein(h, y, lh, ly, decoder, PHONEME_MAP):\n",
        "\n",
        "    # h - ouput from the model. Probability distributions at each time step \n",
        "    # y - target output sequence - sequence of Long tensors\n",
        "    # lh, ly - Lengths of output and target\n",
        "    # decoder - decoder object which was initialized in the previous cell\n",
        "    # PHONEME_MAP - maps output to a character to find the Levenshtein distance\n",
        "\n",
        "    h = h.permute(1, 0, 2)# TODO: You may need to transpose or permute h based on how you passed it to the criterion\n",
        "    # Print out the shapes often to debug\n",
        "    t1 =time.time()\n",
        "    beam_results, _, _, out_lens = decoder.decode(h,seq_lens=lh)\n",
        "    t2 = time.time()\n",
        "    # print(f\"time cost {t2-t1}\")\n",
        "    # TODO: call the decoder's decode method and get beam_results and out_len (Read the docs about the decode method's outputs)\n",
        "    # Input to the decode method will be h and its lengths lh \n",
        "    # You need to pass lh for the 'seq_lens' parameter. This is not explicitly mentioned in the git repo of ctcdecode.\n",
        "\n",
        "    batch_s = h.shape[0]# TODO\n",
        "    # print(f\"batch_szie {batch_size}\")\n",
        "\n",
        "    dist = 0\n",
        "\n",
        "    # dist = 0\n",
        "    # h = np.zeros((100,))  \n",
        "    # y = y.cpu().detach().numpy().astype(int)\n",
        "    for i in range(batch_s): # Loop through each element in the batch\n",
        "\n",
        "    # for j in range(100)\n",
        "        h_sliced = beam_results[i][0][:out_lens[i,0]]\n",
        "    # print(h_sliced.shape)\n",
        "        # TODO: Get the output as a sequence of numbers from beam_results\n",
        "        # Remember that h is padded to the max sequence length and lh contains lengths of individual sequences\n",
        "        # Same goes for beam_results and out_lens\n",
        "        # You do not require the padded portion of beam_results - you need to slice it with out_lens \n",
        "        # If it is confusing, print out the shapes of all the variables and try to understand\n",
        "\n",
        "        h_string = \"\".join([PHONEME_MAP[j] for j in h_sliced])# TODO: MAP the sequence of numbers to its corresponding characters with PHONEME_MAP and merge everything as a single string\n",
        "        # print(f\"ly.shape {ly.shape}\")\n",
        "        # print(f\"y.shape {y.shape}\")\n",
        "        y_sliced = y[i][:ly[i]]\n",
        "        y_string = \"\".join([PHONEME_MAP[j] for j in y_sliced])# TODO: MAP the sequence of numbers to its corresponding characters with PHONEME_MAP and merge everything as a single string\n",
        "        # print(f\"h_string {h_string} h_string.len {len(h_string)}\")\n",
        "        # print(f\"y_string {y_string} y_string.len {len(y_string)}\")\n",
        "        per_dist = Levenshtein.distance(h_string, y_string)\n",
        "        # print(f\"{i} {per_dist} \")\n",
        "        dist += per_dist\n",
        "\n",
        "    dist/=batch_s\n",
        "    return dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD5mpzYmyZ5S",
        "outputId": "9d9789e3-4c91-4f71-cd1d-78cd7432bc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  48\n",
            "Train dataset samples = 28539, batches = 595\n",
            "Val dataset samples = 2703, batches = 57\n",
            "Test dataset samples = 2620, batches = 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/11785/hw3p2/HW3 Starter/model/0.4600294232368469_10_05_04_2022_22_12_13model.pth\"))\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    # num_correct = 0\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc=f'Train epoch: {epoch+1}') \n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    desc = \"start\"\n",
        "    # tq = tqdm(train_loader, desc=desc,dynamic_ncols=True)\n",
        "    # with tqdm(train_loader, desc=desc,dynamic_ncols=True) as tq:\n",
        "    for i, (x, y, lx, ly) in enumerate(train_loader):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        # lx = (lx/2).type(torch.LongTensor)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            out, out_len = model(x,lx)\n",
        "            loss = criterion(out,y.permute(1,0), out_len, ly)\n",
        "        total_loss += loss\n",
        "        # desc = \"loss = {:.04f}\".format(float(total_loss / (i + 1)))\n",
        "        # desc += \"lr = {:.04f}\".format(float(optimizer.param_groups[0]['lr']))\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        # loss.backward()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        # optimizer.step()\n",
        "        # scheduler.step()\n",
        "        # tq.update()\n",
        "        scaler.update()\n",
        "        batch_bar.update()\n",
        "        torch.cuda.empty_cache() \n",
        "    batch_bar.close()\n",
        "    \n",
        "    tqdm.write(\"Epoch {}/{}: Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "        epoch + 1,\n",
        "        epochs,\n",
        "        float(total_loss / len(train_loader)),\n",
        "        float(optimizer.param_groups[0]['lr'])))\n",
        "    wandb.log({\"Train Loss\": float(total_loss / len(train_loader))})\n",
        "    wandb.log({\"lr\" : float(optimizer.param_groups[0]['lr'])})\n",
        "\n",
        "    # if epoch%5==0:\n",
        "    model.eval()\n",
        "    \n",
        "    t_val_loss = 0\n",
        "    for i, data in enumerate(val_loader, 0):\n",
        "        spectrograms, labels, input_lengths, label_lengths = data\n",
        "        # print(f\"label_lengths {label_lengths}\")\n",
        "        spectrograms, labels =spectrograms.to(device), labels\n",
        "        # input_lengths = (input_lengths/2).type(torch.LongTensor)\n",
        "        with torch.no_grad():\n",
        "            out,out_lengths = model(spectrograms,input_lengths)\n",
        "        t_val_loss += criterion(out,labels.permute(1,0), out_lengths, label_lengths)\n",
        "        \n",
        "    val_loss = t_val_loss/len(val_loader)\n",
        "    scheduler.step(val_loss)\n",
        "    tqdm.write(\"Epoch {}/{}: val loss {:.04f}\".format(\n",
        "            epoch + 1,\n",
        "            epochs,\n",
        "            float(val_loss),\n",
        "            ))\n",
        "    \n",
        "    wandb.log({\"val_loss\" : float(val_loss)})\n",
        "    now_name = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
        "    torch.save(model.state_dict(), f\"/content/drive/MyDrive/11785/hw3p2/HW3 Starter/model/{float(val_loss)}_{epoch}_{now_name}model.pth\")\n",
        "    if epoch%5==0:\n",
        "        t_dist = 0\n",
        "        for i, data in enumerate(val_loader, 0):\n",
        "            spectrograms, labels, input_lengths, label_lengths = data\n",
        "            # print(f\"label_lengths {label_lengths}\")\n",
        "            spectrograms, labels =spectrograms.to(device), labels\n",
        "            # input_lengths = (input_lengths/2).type(torch.LongTensor)\n",
        "            with torch.no_grad():\n",
        "                out,out_lengths = model(spectrograms,input_lengths)\n",
        "            t_dist = calculate_levenshtein(out, labels.permute(1,0), out_lengths, label_lengths, decoder, PHONEME_MAP)\n",
        "            break\n",
        "        # dist = t_dist/len(val_loader)\n",
        "        wandb.log({\"dist\" : float(t_dist)})\n",
        "        tqdm.write(\"distance {:.04f}\".format(\n",
        "            float(t_dist),\n",
        "            ))\n",
        "    #     true_y_list = []\n",
        "    #     pred_y_list = []\n",
        "    #     with torch.no_grad():\n",
        "    #         for i in range(1):\n",
        "    #         # X = test_samples[i]\n",
        "\n",
        "    #         # test_items = test_item(X, context=args['context'])\n",
        "    #         # test_loader = torch.utils.data.DataLoader(test_items, batch_size=args['batch_size'], shuffle=False)\n",
        "\n",
        "    #             for x, lx in test_loader:\n",
        "    #             # data = data.float().to(device)\n",
        "    #                 x = x.cuda()\n",
        "    #                 # y = y.cuda()\n",
        "    #                 out, out_len = model(x,lx)\n",
        "    #                 pred_y = pred(out,out_len,decoder,PHONEME_MAP)\n",
        "    #             # print(out.shape)\n",
        "    #             # pred_y = torch.argmax(out, axis=2)\n",
        "    #             # print(pred_y.shape)\n",
        "    #                 pred_y_list.extend(pred_y)\n",
        "    # # print(pred_y_list)\n",
        "    # # now_name = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
        "    #     f = open(f\"bad.csv\", \"w\")\n",
        "    #     f.write(\"id,predictions\\n\")\n",
        "    #     for idx, i  in enumerate(pred_y_list):\n",
        "    #         f.write(f\"{idx},{i}\\n\")\n",
        "    #     f.close()\n",
        "    #     kaggle.api.competition_submit('bad.csv','nice','11-785-s22-hw3p2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApdAibz3zI6J",
        "outputId": "1fbc0a66-fbfd-4010-c974-8da87c387b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100: Train Loss 2.4969, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100: val loss 1.4145\n",
            "distance 32.5208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100: Train Loss 1.1998, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100: val loss 1.1354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100: Train Loss 1.0155, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100: val loss 1.0584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100: Train Loss 0.9473, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100: val loss 0.9980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100: Train Loss 0.9075, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100: val loss 0.9718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100: Train Loss 0.8829, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100: val loss 0.9283\n",
            "distance 21.4792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100: Train Loss 0.8633, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100: val loss 0.8861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100: Train Loss 0.8468, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100: val loss 0.8870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100: Train Loss 0.8311, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100: val loss 0.8745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100: Train Loss 0.8199, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100: val loss 0.8465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100: Train Loss 0.8099, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100: val loss 0.9080\n",
            "distance 20.2292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100: Train Loss 0.8006, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100: val loss 0.8344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100: Train Loss 0.7945, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100: val loss 0.8507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100: Train Loss 0.7877, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100: val loss 0.8834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100: Train Loss 0.7824, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100: val loss 0.9205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100: Train Loss 0.7788, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100: val loss 0.8328\n",
            "distance 19.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100: Train Loss 0.7746, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100: val loss 0.8065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100: Train Loss 0.7709, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100: val loss 0.8450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100: Train Loss 0.7674, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100: val loss 0.8112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100: Train Loss 0.7629, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100: val loss 0.8261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100: Train Loss 0.7606, Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100: val loss 0.8281\n",
            "distance 19.1667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100: Train Loss 0.7232, Learning Rate 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100: val loss 0.7590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100: Train Loss 0.7211, Learning Rate 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100: val loss 0.7294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100: Train Loss 0.7175, Learning Rate 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100: val loss 0.7581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100: Train Loss 0.7153, Learning Rate 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100: val loss 0.7357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100: Train Loss 0.7127, Learning Rate 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100: val loss 0.7318\n",
            "distance 16.6458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100: Train Loss 0.7093, Learning Rate 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100: val loss 0.7318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100: Train Loss 0.6793, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100: val loss 0.7094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100: Train Loss 0.6766, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100: val loss 0.7100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100: Train Loss 0.6753, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100: val loss 0.6953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100: Train Loss 0.6724, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100: val loss 0.6940\n",
            "distance 16.2083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100: Train Loss 0.6716, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100: val loss 0.7154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100: Train Loss 0.6677, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100: val loss 0.6933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100: Train Loss 0.6676, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100: val loss 0.7122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100: Train Loss 0.6667, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100: val loss 0.6916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100: Train Loss 0.6649, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100: val loss 0.6870\n",
            "distance 15.7292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100: Train Loss 0.6616, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100: val loss 0.7248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/100: Train Loss 0.6616, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/100: val loss 0.6800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/100: Train Loss 0.6597, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/100: val loss 0.7128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100: Train Loss 0.6590, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100: val loss 0.6913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/100: Train Loss 0.6581, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/100: val loss 0.6949\n",
            "distance 15.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/100: Train Loss 0.6581, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/100: val loss 0.7040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/100: Train Loss 0.6315, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/100: val loss 0.6658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/100: Train Loss 0.6312, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/100: val loss 0.6539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/100: Train Loss 0.6302, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/100: val loss 0.6509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/100: Train Loss 0.6291, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/100: val loss 0.6497\n",
            "distance 15.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/100: Train Loss 0.6278, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/100: val loss 0.6508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/100: Train Loss 0.6258, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/100: val loss 0.6531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/100: Train Loss 0.6245, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/100: val loss 0.6599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100: Train Loss 0.6235, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100: val loss 0.6512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/100: Train Loss 0.6030, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/100: val loss 0.6190\n",
            "distance 14.7708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/100: Train Loss 0.6005, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/100: val loss 0.6237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/100: Train Loss 0.6013, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/100: val loss 0.6327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/100: Train Loss 0.6000, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/100: val loss 0.6327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/100: Train Loss 0.5994, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/100: val loss 0.6213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/100: Train Loss 0.5805, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/100: val loss 0.5866\n",
            "distance 13.7083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/100: Train Loss 0.5797, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/100: val loss 0.6041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/100: Train Loss 0.5797, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/100: val loss 0.5937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/100: Train Loss 0.5781, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/100: val loss 0.5960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/100: Train Loss 0.5783, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/100: val loss 0.5912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/100: Train Loss 0.5630, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/100: val loss 0.5812\n",
            "distance 13.6042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/100: Train Loss 0.5629, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/100: val loss 0.5814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/100: Train Loss 0.5616, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/100: val loss 0.5760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/100: Train Loss 0.5612, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/100: val loss 0.5823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/100: Train Loss 0.5611, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/100: val loss 0.5771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/100: Train Loss 0.5587, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/100: val loss 0.5764\n",
            "distance 13.2083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/100: Train Loss 0.5585, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/100: val loss 0.5811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/100: Train Loss 0.5482, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/100: val loss 0.5657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/100: Train Loss 0.5467, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/100: val loss 0.5634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/100: Train Loss 0.5458, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/100: val loss 0.5665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/100: Train Loss 0.5466, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/100: val loss 0.5700\n",
            "distance 12.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/100: Train Loss 0.5451, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/100: val loss 0.5674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/100: Train Loss 0.5451, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/100: val loss 0.5664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/100: Train Loss 0.5357, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/100: val loss 0.5576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/100: Train Loss 0.5361, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/100: val loss 0.5524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/100: Train Loss 0.5360, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/100: val loss 0.5536\n",
            "distance 12.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77/100: Train Loss 0.5349, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77/100: val loss 0.5560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78/100: Train Loss 0.5351, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78/100: val loss 0.5557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch: 79:  97%|█████████▋| 580/595 [08:41<00:13,  1.11it/s, loss=0.5338, lr=0.0001]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kaggle.api.competition_submit('/home/linjiw/Downloads/hw3/tmp/bad.csv','nice','11-785-s22-hw3p2')"
      ],
      "metadata": {
        "id": "mR0tV7MjzQ7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}